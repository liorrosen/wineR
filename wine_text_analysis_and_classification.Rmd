---
title: "What's in a wine review?"

output:
  html_document: default
  html_notebook: default
---

### I don't understand wine.  Can data fix that? 
I like wine, but in spite of [some](https://infocus.emc.com/william_schmarzo/data-scientist-quest-perfect-wine/) [fun](https://www.r-bloggers.com/data-scientist-with-a-wine-hobby-part-ii/) [analysis](https://murillogroupmsu.com/wine/) of wines recently, I still don't quite understand wines the way I want to. The analysis I'd love to have would simplify all the many ways people describe wines into a few features that show how different kinds of wine relate to one another.

The prototypical example of what I'd love is something similar to what's been done with scotch whiskey. That's thanks to some [nice analysis](http://whiskyanalysis.com/index.php/methodology-introduction/methodology-flavour-comparison/) of [whiskey data](https://www.mathstat.strath.ac.uk/outreach/nessie/nessie_whisky.html), showing that for all the many different ways we can describe them, 50% of the difference among whiskies is due to one of two main features, either the "smokiness" or the "body". By sampling varieties along these axes, you can develop a thoughtful appreciation for whiskey.

Wine seems more complicated. While people typically use around a dozen terms to describe whiskies, people use hundreds of terms to describe wines, and it would be lovely to have a simple framework for parsing how these descriptions relate wines to one another. I compiled a [list](https://github.com/sadacca/wineR/blob/master/wine_terms.txt) capturing ~300 taste-related terms used to describe wine, and the question I'm wondering is: what's the simplest framework we can use to think about the taste of wine? Do we need all ~300 terms to tell reds from whites? How about Pinot Grigio from Pinot Noirs or Merlot from Malbec?

Before we dig into the data - there's one big caveat: if you dye a white wine red, [people start describing the taste in terms of a red wine](http://www.realclearscience.com/blog/2014/08/the_most_infamous_study_on_wine_tasting.html). The down side of this is that our 'taste-terms' might not be based on taste alone. I'm okay with that. The goal here is to better understand wines, and if this data give us information beyond "red wine is different than white wine", that's terrific. And, on the plus side: it should be pretty easy to tell white wines from red.

So first - after loading the wine review data[^1], and cleaning and processing our database of wine reviews we'll create a simple model of how wine reviews map on to our selected wine terms. This very simple model is often called a "bag-of-words" model, with each wine review described by the subset of listed terms identified in that review. While there are many more complex ways of relating our wine reviews to one another eiher using context to identify differences in how these terms are used like in a "skip-gram" model, or relating similar terms (e.g. tannins and tannic) as a single feature, it'd be quite promising if even this simple model could effectively compare wine reviews.

```{r initialize, include=FALSE}
# this was initially written as an R Notebook, 
# by Brian Sadacca - 08/27/17, last tested 08/31/17
# and hosted at www.github.com/sadacca/wineR/
#
# to run, there are several dependencies, including:
# the following packages, multiplot.r (in same repository)
# and data (in the form of wine reviews, collected
# with the scraper in the same repository) 
# there's also an associated shiny app, hosted at
# https://sadacca.shinyapps.io/wine-findr/ 



#initialize all necessary packages
options(warn=-1)

suppressMessages(library(dplyr))
suppressMessages(library(slam))
suppressMessages(library(lsa))
suppressMessages(library(tm))
suppressMessages(library(NLP))
suppressMessages(library(mlr))
suppressMessages(library(ggplot2))
suppressMessages(library(gmodels))
suppressMessages(library(reshape2))

#first, load the wine terms we're going to need
wine_terms<-t(read.csv("wine_terms.txt", sep = ",", header = F))

# then, load the review data, scraped from the web using the scraper in this repository
wine_cellar <- readRDS("wine_collection_V2.RDS")
wine_all <- bind_rows(wine_cellar)


# let's define a function to clean and match reviews to wine terms

clean_review = function(x,wine_terms){
  
  review_terms <- x %>% 
    toupper() %>% 
    removePunctuation() %>% 
    strsplit(" ")
  
  review_vector <- matrix(unlist(review_terms), ncol = 1, byrow = TRUE)
  term_vector <- as.numeric(wine_terms%in%review_vector)
  return(term_vector)
  
}

# let's subset to remove infrequent wines
# and filter out others, if we want
# (e.g. remove blends, keep just one wine type, etc)

wine_all.new <- wine_all # let's not mess up the first file
# there are many varieties at < 10 reviews - not quite fair to try and classify them, right? 
wine_all.new <- wine_all.new %>% group_by(Variety) %>% filter(n() >= 50) %>% ungroup() %>% as.data.frame()
# was initially stripping out all wine blends (Portuguese wines are GREAT!!)
# and forgot to remove this line before starting to pretty up the HTML output.  
wine_all.new <- wine_all.new %>% filter(!grepl("Portuguese",wine_all.new$Variety, fixed=TRUE))


# then, let's use that function on all wine reviews
# by first picking out the reviews
wine_reviews <- wine_all.new["review"]
wine_reviews <- split(wine_reviews,seq(nrow(wine_reviews)))

# then by snatching the IDs for each wine
wine_IDs <- wine_all.new["Variety"]
wine_IDs <- unlist(split(wine_IDs, seq(nrow(wine_IDs))))

# then using the function we made on each review
term_matrix <- lapply(wine_reviews, function(x) clean_review(x,wine_terms))
term_matrix <- matrix(unlist(term_matrix), ncol = nrow(wine_all.new), dimnames = list(NULL, wine_IDs))
```



### Can we get a simpler picture of how wines relate by looking for similarities in how wine terms are used?

Now we have a model of wine reviews: ~7000 wine reviews, possessing a combination of ~300 features (where each term is a feature). Given this model, we'll use principal components analysis (PCA) to see if there are a few features that help separate wines from one another, with these features being principle components (PCs) of the PCA composed of weighted combinations of wine terms.


```{r pca_calc_and_projection, include=TRUE, echo = FALSE, results='hide', fig.height=9, fig.width=9}
options(warn=-1)
## OK.  So we've got ~280 features (terms) to judge wine similarity
## can we use these to break down wine varieties in an interpretable way? 

## to simplify the 280, let's do PCA on that term matrix
pc_results <- prcomp(t(term_matrix))

## and bind wine features to the PCS for easy sorting 
pcs <- cbind(pc_results$x,wine_all.new)

## now let's structure a plot on the basis of wine types -- 
#perhaps red vs white vs rose?
plt1 <- ggplot(subset(pcs,Variety %in% c("White Blend","Rosé", "Red Blend")), 
               aes(x = PC1, y = PC2, colour = Variety)) + geom_point( alpha = 1/2) + #xlim(-.004, .044) + ylim(-.041, .025) + 
  guides(col = guide_legend(nrow = 2)) + theme(legend.position = "bottom")

#the big grapes?  
plt2 <- ggplot(subset(pcs,Variety %in% c("Chardonnay",  "Sauvignon Blanc", "Merlot","Cabernet Sauvignon","Sangiovese")), 
               aes(x = PC1, y = PC2, colour = Variety)) + geom_point( alpha = 1/2)  + #xlim(-.004, .044) + ylim(-.041, .025) + 
  guides(col = guide_legend(nrow = 2))+  theme(legend.position = "bottom")

#some little grapes?
plt3 <- ggplot(subset(pcs,Variety %in% c("Gr?ner Veltliner", "Viognier", "Cabernet Franc","Malbec", "Nebbiolo")), 
               aes(x = PC1, y = PC2, colour = Variety)) + geom_point( alpha = 1/2) + #xlim(-.004, .044) + ylim(-.041, .025) + 
  guides(col = guide_legend(nrow = 2))+  theme(legend.position = "bottom")

#desserts, ports and bubbly?
plt4 <- ggplot(subset(pcs,Category %in% c("Dessert", "Sparkling","Port/Sherry")), 
               aes(x = PC1, y = PC2, colour = Category)) + geom_point( alpha = 1/2) + #xlim(-.004, .044) + ylim(-.041, .025) + 
  guides(col = guide_legend(nrow = 2))+ theme(legend.position = "bottom")


source("multiplot.r") #it's googleable, also in the gitRepo
multiplot(cols = 2, plt1,plt2,plt3,plt4)

```
 
 
So, this is pretty nice for our simplified model. Each plot shows a subset of wines from the database, projected onto the two features that best show the differences among individual wines (PC1 and PC2).  Based on these features, we can tell white wines from reds just like we expected. This is clearest in the top-left plot, showing all wines labeled as Red Blends, White Blends, or Rosé (which can be made from either traditionally red or white grapes and often has similarities to both red and white wines).  As a nice sanity check, it looks like Rosé wines fall right across both the red and white distributions, connecting the two. One surprise is that the difference within red and white wines is just as big as the differences between whites and reds.  What's particularly striking about this spread is that the differences between reds and whites is along a single feature - PC1. This is in contrast with PC2, which captures little difference between reds and whites, but instead captures much of the variability within each category.  One takeaway is that that different words are used to describe red and white wines, which will be loaded heavily on PC1.  Though nice, with all the individual datapoints for each wine overlain in each of these scatter plots, it's tough to get a sense for exactly how each wine variety, on average, relates to all the others. If we take the center of each wine variety's cloud of individual wine reviews, do we see a similar pattern of variation among wine varieties?

  

```{r pca_calc_and_projection_group_means, include=TRUE, echo = FALSE, results='hide', fig.height=8, fig.width=9}
suppressMessages(library(ggrepel))

# note that this pc_wineload =/= the aggregated data for the shiny app
# that also aggregates by group (there are both white and red Pino Noirs.. did you know?)
# though the results are similar, aside from the extra varieties (and blurring some of the categories)
# fwiw this makes classification a *slightly* harder than it should otherwise be 
pc_wineload = aggregate(pcs[1:150], by= list(pcs$Variety), FUN = mean)
ggplot(pc_wineload, aes(x = PC1, y = PC2, label= Group.1))+ geom_point(color = 'orange')+geom_label_repel(label.size =NA, fontface = "bold", size = 3)

```
 
 
 
This is a terrific bit of insight into how varietals compare to one another, on average. While the spread of these group means aren't as big as the spread in individual examples, there is still variation within the white and red clusters (with a fun little "really red" group now visible out at the top right corner of the plot), with variation among reds still primarily along PC1 and whites still along PC2.  This visualization gives us a simple framework for thinking about different grapes, in a way that seems pretty sensible. Now, what are the terms that were important for making these principle components?  To get a better sense, let's check out how individual words contribute to the first two PCs.
 
 
 
```{r pca_loadings_plot, include=TRUE, results='hide', echo = FALSE, fig.height=8, fig.width=9}

# render the terms from the pca
textplt1 <- ggplot(as.data.frame(pc_results$rotation), aes(x=PC1, y=PC2, label = wine_terms)) + geom_text(check_overlap=TRUE,fontface = "bold", size = 3)#+
#+geom_label(label.size =NA, fontface = "bold", size = 3) +
  #xlim(-4, 28) + ylim(-19, 10) 

plot(textplt1)

```
 
  
Ok so this makes sense, PC1 seems to call out a number of big red wine terms, as tannins, cherry, spice and raspberry flavour all play a big role in PC1, perhaps why the spread of red wines was greatest on PC1. Similarly, the spread of whites was greatest on PC2, and in fact PC2 seems to be loaded with many traditionally white-wine terms: apple, lemon, pear, peach, and lime all fall heavily on this axis.
 
 
 
### Can we identify what kind of wine was reviewed based on these features? 

If we have all this information to tell apart wines, how well can we do at classifying wines by category or varietal from these terms? Does this model actually distil useful information? To start, let's do a quick classification of just the "Big" wines - varieties that have more than 300 reviews in our database - can we tell them apart? For this classification we'll use support vector machines on reviews projected onto the first few principle components, though any classifier that can handle multiple classes performs well.
 
 
```{r classification_trial, include=TRUE, results='hide', echo = FALSE, fig.height=6, fig.width=8}

# structure of the intial classification taken from mlr docs
# for most code blocks - filtering the data (mldata) precedes 
# construction of the task, learner, train/test split, model fitting and prediction
# there was a code block initially devoted to finding the best classifier 
# with mlr's benchmark() function - but was secondary to addressing wine dimensionality 

pcs2 <- pcs %>% group_by(Variety) %>% filter(n() >= 300) %>% ungroup() %>% as.data.frame()
pcs2 <- pcs2 %>% filter(!grepl("Blend",pcs2$Variety, fixed=TRUE))


mldata = cbind(pcs2[,1:150],pcs2[,296])
colnames(mldata)[151] <- "Variety"


## 1) Define the task
## Specify the type of analysis (e.g. classification) and provide data and response variable
task = makeClassifTask(data = mldata, target = "Variety")

## 2) Define the learner
## Choose a specific algorithm (e.g. linear discriminant analysis)
lrn = makeLearner("classif.svm") #svm and randomForest reliably best, then LDA, of all things with glmnet, xgboost and naivebayes o.k.

n = nrow(mldata)
train.set = sample(n, size = 2/3*n)
test.set = setdiff(1:n, train.set)

## 3) Fit the model
## Train the learner on the task using a random subset of the data as training set
model = train(lrn, task, subset = train.set)

## 4) Make predictions
## Predict values of the response variable for new observations by the trained model
## using the other part of the data as test set
pred = predict(model, task = task, subset = test.set)

## 5) Evaluate the learner
## Calculate the mean misclassification error and accuracy
performance(pred, measures = list(mmce, acc, ber, kappa))

predconfmat <- calculateConfusionMatrix(pred = pred)

## before plotting we need to scale the data (to the percent of wines classified per bin per column)
#predconfmat$result <- t(scale(t(predconfmat$result), center = FALSE, scale = TRUE))
predconfmat$result <- t(apply(predconfmat$result, 1, function(x)100*(x-min(x))/(max(x)-min(x))))


## now sort those wines in a sensible way for ordering the wines
pc_wineload = aggregate(pcs2$PC1+pcs2$PC2, by= list(pcs2$Variety), FUN = mean)

image = qplot(x = true, y = predicted, fill=value, data=(melt(predconfmat$result[order(pc_wineload$x),order(pc_wineload$x)])),geom="raster")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))+scale_fill_continuous(name = "classification %:")
plot(image)

```


They look like they classify pretty well: on average 75% of reviews were correctly assigned to the variety they belonged to. For the most part, we can tell that a wine came from a particular variety and if we're misclassifying, it's not just random. We're misclassifying based on wines that taste similarly, as if some Pinot Noirs really taste like (or, were described like) a Cabernet.

Here's an interesting thought: Could we use this model to find individual wines that are particularly good examples of their class (like an ur-merlot) or wines that really taste like other things (e.g. can I find a cabernet that tastes like a white wine?). In fact, I just wrote a shiny app to do this, [right here](https://sadacca.shinyapps.io/wine-findr/) if you're interested in playing with the underlying data.

Until then - let's get back to our question: how well can we really tell apart wines based on these reviews, and how many features do we need to do that?


### How many features do you need to identify wines by category or variety? 
 
```{r classification_how_many_PCs, include=TRUE, echo = FALSE, results='hide',fig.height=4, fig.width=12}
## ok - we can classify AND have a sense of what works best
## now, how many dimensions are required to really reach this level of effective classification
## or, to put it another way: what's the dimensionality of wine taste ?
## while many of the terms used to describe wines covary, and some of the terms 
## reliably distingish wines quite well (e.g. cherry, tannins, pinapple) 
## we have ~270 potential terms to describe wines by -- how many actually contribute 
## to successfully telling the difference amongst wines by category or variety? 


## to get a sense of the dimensionality - let's look at the eigenvalues
## some UGLY shoehorning going on here, just to get the formatting right for ggplot
## there's an easier way, for sure, but it's still early-days with R for me
ydata = data.frame(matrix(ncol = 1, nrow = length(pc_results$sdev)))
ydata[1] <- 100*pc_results$sdev/sum(pc_results$sdev)
ydata <- as.data.frame(tibble::rownames_to_column(ydata,"PC #"))
ydata["PC #"]<- as.double(unlist(ydata["PC #"]))
colnames(ydata[2]) <- "% Variance Explained"
colnames(ydata) <-c("PC #", "% Variance Explained")

ydata1=as.data.frame(ydata)

ydata = data.frame(matrix(ncol = 1, nrow = length(pc_results$sdev)))
ydata[1] <- 100*cumsum(pc_results$sdev/sum(pc_results$sdev))
ydata <- as.data.frame(tibble::rownames_to_column(ydata,"PC #"))
ydata["PC #"]<- as.double(unlist(ydata["PC #"]))
colnames(ydata) <-c("PC #", "% Cumulative Variance Explained")

ydata2=as.data.frame(ydata)

plt1<- ggplot(ydata1) + 
  geom_line(aes(x = `PC #`, y = `% Variance Explained`), size = 1)

plt2<- ggplot(ydata2) + 
  geom_line(aes(x = `PC #`, y = `% Cumulative Variance Explained`), size = 1)

multiplot(plt1,plt2, cols = 2)


```


When deciding how many features (like our principle components) to include in simplified model of the underlying data, there are a few common heuristics. One commonly used with PCA is the "elbow method" to pick the PC past which all PCs have a similar and low ability to explain the variance in the data. This is done using a "scree plot" of eigenvalues for the principle components analysis, plotted above on the left. Each PC has a decreasing ability to explain the variation among wine reviews. Beyond 12 PCs, each additional PC adds a small bit of explanatory power. One other common heuristic uses the percent of the total variance explained to choose features; by this approach we'd need 150-200 dimensions to explain 90% of the total variance among wine reviews. For my question, the key problem with these heuristics is that they're both focused on any and all variance in the underlying data, and my interest was a bit more specific. My initial question was: how many features were required to tell wines apart, either by category (white from red) or variety (Cabernet from Pinot). One solution is to simply classify the data with different numbers of features and see how well the classification performs. With this approach we can ask a very specific question that addresses my initial goal: how many dimensions do we need to get to 80% or 90% of our peak ability to classify?


```{r classification_how_many_PCs3, include=TRUE, echo = FALSE, results='hide'}


## how does this relate to our ability to classify? 
# let's make a function to ease fitting a few things

fit_pca_data<-function(pcs2, group2fit, niter, npcs){
  
  pcs_ctr <- 0
  class_performance = matrix(data=NA, nrow=length(npcs), ncol=niter)
  
  
  for (numpcs in npcs){
    pcs_ctr <-pcs_ctr+1
    
    for (niter in c(1:niter)){
      
      if (group2fit == "Variety"){
        mldata <- cbind(pcs2[,1:numpcs],pcs2[,296])
        colnames(mldata)[numpcs+1] <- "Target"
      }
      
      if (group2fit == "Category"){
        mldata <- cbind(pcs2[,1:numpcs],pcs2[,297])
        colnames(mldata)[numpcs+1] <- "Target"
      }
      
      if (numpcs == 1){
        colnames(mldata)[1:numpcs] <- "pcs"
        
        mldata <- as.data.frame(mldata)
      }
      
      # set up the classification via MLR: task, learner, subsetting, model, prediction
      task = makeClassifTask(data = mldata, target = "Target")
      lrn = makeLearner("classif.svm") #svm and ksvm best, then cforest, next glmnet then xgboost good too
      
      n = nrow(mldata)
      train.set = sample(n, size = 2/3*n)
      test.set = setdiff(1:n, train.set)
      
      model = train(lrn, task, subset = train.set)
      pred = predict(model, task = task, subset = test.set)
      
      ## 5) Evaluate the learner
      ## Calculate the mean misclassification error and accuracy
      class_performance[pcs_ctr,niter] <- performance(pred, measures = acc)
    }
  }
  return(class_performance)
}


# and now let's fit some stuff


niter = 3
npcs = c(1,2,3,4,6,8,10,15,20,30,40,50,75,100,125,150,200,225,250)


# like the most common wines 

pcs2 <- pcs %>% group_by(Variety) %>% filter(n() >= 300) %>% ungroup() %>% as.data.frame()
pcs2 <- pcs2 %>% filter(!grepl("Blend",pcs2$Variety, fixed=TRUE))
group2fit = "Variety"

class_biggrapes_performance <- fit_pca_data(pcs2, group2fit, niter, npcs )

# or lesser wines 

pcs2 <- pcs %>% group_by(Variety) %>% filter(n() >= 50) %>% ungroup() %>% as.data.frame()
pcs2 <- pcs2 %>% filter(!grepl("Blend",pcs2$Variety, fixed=TRUE))
group2fit = "Variety"

class_smallgrapes_performance <- fit_pca_data(pcs2, group2fit, niter, npcs )


# or or wine categories

pcs2 <- pcs %>% group_by(Variety) %>% filter(n() >= 50) %>% ungroup() %>% as.data.frame()
pcs2 <- subset(pcs2,Category %in% c("White", "Red"))
group2fit = "Category"

class_category_performance <- fit_pca_data(pcs2, group2fit, niter, npcs )

## and then aggregate the measures of interest

class_category_performance_t = as.data.frame(class_category_performance)
class_nmean <- apply(class_category_performance_t,1,function(x) mean(na.omit(x)))
class_nmean <- class_nmean/max(class_nmean)
class_sd <- apply(class_category_performance_t,1,function(x) sd(na.omit(x)/max(class_nmean)))
xdata1 = as.data.frame(cbind(npcs,class_nmean,class_sd))

class_biggrapes_performance_t = as.data.frame(class_biggrapes_performance)
class_nmean2 <- apply(class_biggrapes_performance_t,1,function(x) mean(na.omit(x)))
class_nmean2 <- class_nmean2/max(class_nmean2)
class_sd2 <- apply(class_biggrapes_performance_t,1,function(x) sd(na.omit(x)/max(class_nmean2)))
xdata2 = as.data.frame(cbind(npcs,class_nmean2,class_sd2))

class_smallgrapes_performance_t = as.data.frame(class_smallgrapes_performance)
class_nmean3 <- apply(class_smallgrapes_performance_t,1,function(x) mean(na.omit(x)))
class_nmean3 <- class_nmean3/max(class_nmean3)
class_sd3 <- apply(class_smallgrapes_performance_t,1,function(x) sd(na.omit(x)/max(class_nmean3)))
xdata3 = as.data.frame(cbind(npcs,class_nmean3,class_sd3))

xdata = Reduce(merge, list(xdata1, xdata2, xdata3))

## and plot the classifier output

plt1 <- ggplot(xdata) + 
  geom_line(aes(x = npcs, y = class_nmean, color = "c1"), size = 1) +
  geom_ribbon(aes(x = npcs, ymin = class_nmean - 2*class_sd, ymax = class_nmean + 2*class_sd), alpha = 0.3) +

  geom_line(aes(x = npcs, y = class_nmean2, color = "c2"), size = 1) +
  geom_ribbon(aes(x = npcs, ymin = class_nmean2 - 2*class_sd2, ymax = class_nmean2 + 2*class_sd2), alpha = 0.3) +

  geom_line(aes(x = npcs, y = class_nmean3, color = "c3"), size = 1) +
  geom_ribbon(aes(x = npcs, ymin = class_nmean3 - 2*class_sd3, ymax = class_nmean3 + 2*class_sd3), alpha = 0.3) +
  
  
  xlab('number of PCs')+ylab('fraction of total classifcation') + 
  
  scale_colour_manual(name = 'Classification of:', 
                      values =c('c1'='Blue','c2'='Orange','c3'='Red'), labels = c('Category','5 Big Varieties','All Varieties'))+
  
  scale_x_log10(breaks = npcs[c(1:10,12,14,16,19)], limits = c(.9, 251))

plot(plt1)

```



As it turns out (perhaps unsurprisingly) it looks like the number of relevant dimensions for thinking about wine taste depends highly on context. The above plot normalizes classification accuracy to the peak accuracy for each kind of classification (classifying wines by category had a cross-validated accuracy of 95%, while the classifier was 75% accurate with big grapes and 60% accurate telling apart all varieties). In the context of telling broad categories of wines apart, all you need are the 2 dimensions plotted earlier. These give you 95% of your ability to classify reds from whites. While these two dimensions also allow you to tell apart some wine varieties (giving you >50% of your total ability to classify wines), to do better you need to consider more ways in which wines vary. Somewhere between 6 and 15 dimensions are needed to give us 80% of our classification ability, with ~50 dimensions giving us near-peak classification performance. So how many dimensions are required to understand how wines vary from one another? Either 2 features if you're trying to understand the differences between reds and whites but somewhere between 6-12 features are needed to understand the differences among individual wine varieties.



----------------------------------------------------------------------------------------------------------------------------
written by Brian Sadacca, 8.30.2017

[^1]: for all code see associated git repository, code for this was wine_text...Rmd : [https://www.github.com/sadacca/wineR].







